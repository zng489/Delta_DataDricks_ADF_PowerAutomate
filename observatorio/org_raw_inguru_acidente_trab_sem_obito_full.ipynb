{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def API_INGURU(url, per_page, start_date, end_date):\n",
    "    headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "    'accept':'application/json',\n",
    "    'authorization': '6f64d6a047fad369d35c3806f8f8e0560475075a432585973f91caae35b4ad74'\n",
    "    } \n",
    "\n",
    "    params = {\n",
    "        'per_page': per_page,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'sort': '1'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def divide_data(data_inicial, data_final):\n",
    "    formato_data = '%d/%m/%Y %H:%M'\n",
    "\n",
    "    data_inicial = datetime.strptime(data_inicial, formato_data)\n",
    "    data_final = datetime.strptime(data_final, formato_data)\n",
    "    intervalo = data_final - data_inicial\n",
    "    data_final = data_inicial + intervalo // 2\n",
    "    data_final = data_final.replace(hour=23, minute=59, second=59) # define o final como o último segundo do minuto\n",
    "    data_final = data_final.strftime(formato_data)\n",
    "    data_inicial = data_inicial.strftime(formato_data)\n",
    "    return (data_inicial, data_final)\n",
    "\n",
    "\n",
    "def get_news(data_inicial, data_final, id):\n",
    "    url = 'https://app.inguru.me/api/v1/taxonomies/nodes/news/'+str(id)\n",
    "\n",
    "    array_dfs = []\n",
    "\n",
    "    getted_news = 0\n",
    "    \n",
    "    total_news = API_INGURU(url, 1, data_inicial, data_final)['pagination']['total']\n",
    "\n",
    "    \n",
    "    if not total_news:\n",
    "        parcial_data_inicial = data_inicial\n",
    "        parcial_data_final = data_final\n",
    "        dados = {\n",
    "        'author': np.nan,\n",
    "        'content': np.nan,\n",
    "        'crawled_date': np.nan,\n",
    "        'domain': np.nan,\n",
    "        'id': np.nan,\n",
    "        'published_date': np.nan,\n",
    "        'source': np.nan,\n",
    "        'source_country': np.nan,\n",
    "        'source_state': np.nan,\n",
    "        'subtitle': np.nan,\n",
    "        'title': np.nan,\n",
    "        'url': np.nan,\n",
    "        'dh_insertion_raw': np.nan\n",
    "        }\n",
    "        fail_df = pd.DataFrame(dados, index=[0])\n",
    "        array_dfs.append(fail_df)\n",
    "        parcial_data_inicial = parcial_data_final\n",
    "        parcial_data_final = data_final\n",
    "    else:\n",
    "        \n",
    "        print('Total de notícias: ', total_news)\n",
    "\n",
    "        parcial_data_inicial = data_inicial\n",
    "        parcial_data_final = data_final\n",
    "\n",
    "        while getted_news < total_news:\n",
    "\n",
    "            parcial_news = total_news\n",
    "\n",
    "            while parcial_news > 10000:\n",
    "                print('Parcial de notícias: ', parcial_news)\n",
    "                parcial_data_inicial, parcial_data_final = divide_data(parcial_data_inicial, parcial_data_final)\n",
    "                parcial_news = API_INGURU(url, 1, parcial_data_inicial, parcial_data_final)['pagination']['total']\n",
    "\n",
    "            print(\"fazendo requisicao\")\n",
    "            print('Data inicial: ', parcial_data_inicial)\n",
    "            print('Data final: ', parcial_data_final)\n",
    "            news = API_INGURU(url, parcial_news, parcial_data_inicial, parcial_data_final)['data']\n",
    "\n",
    "            #CRIA UM DATAFRAME COM AS NOTICIAS\n",
    "            noticias = pd.DataFrame(news)\n",
    "            #ADICIONA NUM ARRAY DE DATAFRAME\n",
    "            array_dfs.append(noticias)\n",
    "\n",
    "            #corrige as datas\n",
    "\n",
    "            parcial_data_inicial = parcial_data_final\n",
    "            parcial_data_final = data_final\n",
    "\n",
    "            getted_news += parcial_news\n",
    "    return pd.concat(array_dfs)\n",
    "\n",
    "\n",
    "def insere_news(data_inicial, data_final, id, path):\n",
    "    url = 'https://app.inguru.me/api/v1/taxonomies/nodes/news/'+str(id)\n",
    "\n",
    "    array_dfs = []\n",
    "\n",
    "    getted_news = 0\n",
    "\n",
    "    total_news = API_INGURU(url, 1, data_inicial, data_final)['pagination']['total']\n",
    "\n",
    "    if total_news:\n",
    "        \n",
    "    #     print('Total de notícias: ', total_news)\n",
    "\n",
    "        parcial_data_inicial = data_inicial\n",
    "        parcial_data_final = data_final\n",
    "\n",
    "        while getted_news < total_news:\n",
    "\n",
    "            parcial_news = total_news\n",
    "\n",
    "            while parcial_news > 10000:\n",
    "    #         print('Parcial de notícias: ', parcial_news)\n",
    "                parcial_data_inicial, parcial_data_final = divide_data(parcial_data_inicial, parcial_data_final)\n",
    "                parcial_news = API_INGURU(url, 1, parcial_data_inicial, parcial_data_final)['pagination']['total']\n",
    "\n",
    "    #       print(\"fazendo requisicao\")\n",
    "    #       print('Data inicial: ', parcial_data_inicial)\n",
    "    #       print('Data final: ', parcial_data_final)\n",
    "            news = API_INGURU(url, parcial_news, parcial_data_inicial, parcial_data_final)['data']\n",
    "\n",
    "            #CRIA UM DATAFRAME COM AS NOTICIAS\n",
    "            noticias = pd.DataFrame(news)\n",
    "            display(noticias)\n",
    "            #corrige as datas\n",
    "            parcial_data_inicial = parcial_data_final\n",
    "            parcial_data_final = data_final\n",
    "\n",
    "            getted_news += parcial_news\n",
    "\n",
    "\n",
    "            print(\"Total:\", total_news)\n",
    "            print(\"Inseridas:\", getted_news)\n",
    "\n",
    "    else:\n",
    "        print(\"Sem dados\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graph_ids = []\n",
    "    graph_names = []\n",
    "    graph_dfs = []\n",
    "\n",
    "    nodeID = '926' #Declaração do ID\n",
    "\n",
    "    url_nodeID = 'https://app.inguru.me/api/v1/taxonomies/nodes/'+str(nodeID)\n",
    "    IDs = API_INGURU(url = url_nodeID, per_page=1, start_date='', end_date='')['data'][0]\n",
    "    graph_ids.append(IDs['id'])\n",
    "    graph_names.append(IDs['name'].replace(\" \", \"_\"))\n",
    "\n",
    "    #Passa por cada \"filho\" no nó principal, caso não tenha nenhum, nada acontece.\n",
    "    for node_children in IDs['children']:\n",
    "        graph_ids.append(node_children['id'])\n",
    "        graph_names.append(node_children['name'].replace(\" \", \"_\"))\n",
    "\n",
    "    data_inicial = '01/01/2015 00:00'\n",
    "    data_final = datetime.now().strftime(\"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 8774,\n",
       "   'created_at': '2022-05-03 13:44:51',\n",
       "   'updated_at': '2023-02-22 22:56:51',\n",
       "   'name': 'Nodo Raiz',\n",
       "   'expression': '\"ACIDENTE\" OR \"ACIDENTES\"',\n",
       "   'initial_date': None,\n",
       "   'final_date': None,\n",
       "   'color': '#80B62E',\n",
       "   'children': [{'id': 8776,\n",
       "     'created_at': '2022-05-03 13:47:55',\n",
       "     'updated_at': '2023-02-19 20:40:17',\n",
       "     'name': 'CASOS',\n",
       "     'expression': '\"se acidentou\" OR \"acidente ocorreu\" OR \"aconteceu\" OR \"registro\" OR \"registrado\" OR \"sofreu\" OR \"feriu\" OR \"machucou\" AND (\"TRABALHO\" OR \"NO TRABALHO\") NOT (\"morte\" OR \"obito\" OR \"faleceu\" OR \"faleceram\" OR \"morreu\" OR \"morreram\")',\n",
       "     'initial_date': None,\n",
       "     'final_date': None,\n",
       "     'color': '#80B62E',\n",
       "     'children': [],\n",
       "     'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8776'}},\n",
       "    {'id': 8775,\n",
       "     'created_at': '2022-05-03 13:45:23',\n",
       "     'updated_at': '2023-02-22 22:56:51',\n",
       "     'name': 'ACIDENTES DE TRABALHO',\n",
       "     'expression': '\"acidentes de trabalho\" OR \"acidente de trabalho\" OR \"acidente no trabalho\" OR \"acidentes no trabalho\" NOT (\"DIÁRIO OFICIAL\" OR \"FGTS\")',\n",
       "     'initial_date': None,\n",
       "     'final_date': None,\n",
       "     'color': '#80B62E',\n",
       "     'children': [],\n",
       "     'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8775'}}],\n",
       "   'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8774'}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "'accept':'application/json',\n",
    "'authorization': '6f64d6a047fad369d35c3806f8f8e0560475075a432585973f91caae35b4ad74'\n",
    "} \n",
    "nodeID = '926'\n",
    "per_page=1\n",
    "start_date=''\n",
    "end_date=''\n",
    "\n",
    "params = {\n",
    "    'per_page': per_page,\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'sort': '1'\n",
    "}\n",
    "\n",
    "response = requests.get('https://app.inguru.me/api/v1/taxonomies/nodes/'+str(nodeID), headers=headers)\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_ids [8774]\n",
      "graph_names ['Nodo_Raiz']\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "'accept':'application/json',\n",
    "'authorization': '6f64d6a047fad369d35c3806f8f8e0560475075a432585973f91caae35b4ad74'\n",
    "} \n",
    "nodeID = '926'\n",
    "per_page=1\n",
    "start_date=''\n",
    "end_date=''\n",
    "\n",
    "params = {\n",
    "    'per_page': per_page,\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'sort': '1'\n",
    "}\n",
    "\n",
    "response = requests.get('https://app.inguru.me/api/v1/taxonomies/nodes/'+str(nodeID), headers=headers, params=params)\n",
    "response.json()\n",
    "\n",
    "graph_ids = []\n",
    "graph_names = []\n",
    "graph_dfs = []\n",
    "\n",
    "IDs = API_INGURU(url = url_nodeID, per_page=1, start_date='', end_date='')['data'][0]\n",
    "graph_ids.append(IDs['id'])\n",
    "graph_names.append(IDs['name'].replace(\" \", \"_\"))\n",
    "\n",
    "print('graph_ids',graph_ids)\n",
    "print('graph_names',graph_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_ids [8774, 8776, 8775]\n",
      "graph_names ['Nodo_Raiz', 'CASOS', 'ACIDENTES_DE_TRABALHO']\n"
     ]
    }
   ],
   "source": [
    "for node_children in IDs['children']:\n",
    "    graph_ids.append(node_children['id'])\n",
    "    graph_names.append(node_children['name'].replace(\" \", \"_\"))\n",
    "print('graph_ids',graph_ids)\n",
    "print('graph_names',graph_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 8774, 'created_at': '2022-05-03 13:44:51', 'updated_at': '2023-02-22 22:56:51', 'name': 'Nodo Raiz', 'expression': '\"ACIDENTE\" OR \"ACIDENTES\"', 'initial_date': None, 'final_date': None, 'color': '#80B62E', 'children': [{'id': 8776, 'created_at': '2022-05-03 13:47:55', 'updated_at': '2023-02-19 20:40:17', 'name': 'CASOS', 'expression': '\"se acidentou\" OR \"acidente ocorreu\" OR \"aconteceu\" OR \"registro\" OR \"registrado\" OR \"sofreu\" OR \"feriu\" OR \"machucou\" AND (\"TRABALHO\" OR \"NO TRABALHO\") NOT (\"morte\" OR \"obito\" OR \"faleceu\" OR \"faleceram\" OR \"morreu\" OR \"morreram\")', 'initial_date': None, 'final_date': None, 'color': '#80B62E', 'children': [], 'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8776'}}, {'id': 8775, 'created_at': '2022-05-03 13:45:23', 'updated_at': '2023-02-22 22:56:51', 'name': 'ACIDENTES DE TRABALHO', 'expression': '\"acidentes de trabalho\" OR \"acidente de trabalho\" OR \"acidente no trabalho\" OR \"acidentes no trabalho\" NOT (\"DIÁRIO OFICIAL\" OR \"FGTS\")', 'initial_date': None, 'final_date': None, 'color': '#80B62E', 'children': [], 'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8775'}}], 'links': {'news': 'https://app.inguru.me/api/v1/taxonomies/nodes/news/8774'}}\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/01/2015 00:00\n",
      "08/03/2023 14:43\n"
     ]
    }
   ],
   "source": [
    "data_inicial = '01/01/2015 00:00'\n",
    "print(data_inicial)\n",
    "data_final = datetime.now().strftime(\"%d/%m/%Y %H:%M\")\n",
    "print(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raph_ids = []\n",
    "graph_names = []\n",
    "graph_dfs = []\n",
    "\n",
    "nodeID = '927' #Declaração do ID\n",
    "\n",
    "url_nodeID = 'https://app.inguru.me/api/v1/taxonomies/nodes/'+str(nodeID)\n",
    "IDs = API_INGURU(url = url_nodeID, per_page=1, start_date='', end_date='')['data'][0]\n",
    "graph_ids.append(IDs['id'])\n",
    "graph_names.append(IDs['name'].replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passa por cada \"filho\" no nó principal, caso não tenha nenhum, nada acontece.\n",
    "for node_children in IDs['children']:\n",
    "    graph_ids.append(node_children['id'])\n",
    "    graph_names.append(node_children['name'].replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8774, 8776, 8775, 8777, 8780, 8780]\n",
      "['Nodo_Raiz', 'NODO_ACIDENTES_DE_TRABALHO_COM_ÓBITOS', 'NODO_ACIDENTES_DE_TRABALHO_COM_ÓBITOS']\n"
     ]
    }
   ],
   "source": [
    "print(graph_ids)\n",
    "print(graph_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/03/2023 17:26\n",
      "01/03/2023 17:26\n"
     ]
    }
   ],
   "source": [
    "end_date = datetime.now().strftime(\"%d/%m/%Y %H:%M\")\n",
    "print(end_date)\n",
    "\n",
    "start_date = (datetime.now() - timedelta(days=7)).strftime(\"%d/%m/%Y %H:%M\")\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeID = '929'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "'accept':'application/json',\n",
    "'authorization': '6f64d6a047fad369d35c3806f8f8e0560475075a432585973f91caae35b4ad74'\n",
    "} \n",
    " \n",
    "params = {\n",
    "    'per_page': per_page,\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'sort': '1'\n",
    "    }\n",
    "\n",
    "per_page=1\n",
    "start_date=''\n",
    "end_date=''\n",
    "\n",
    "url = 'https://app.inguru.me/api/v1/taxonomies/nodes/news/'+str(id)\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://app.inguru.me/api/v1/taxonomies/nodes/news/'+str(id)\n",
    "\n",
    "array_dfs = []\n",
    "\n",
    "getted_news = 0\n",
    "\n",
    "total_news = API_INGURU(url, 1, data_inicial, data_final)['pagination']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(data_inicial, data_final, id):\n",
    "    url = 'https://app.inguru.me/api/v1/taxonomies/nodes/news/'+str(id)\n",
    "\n",
    "    array_dfs = []\n",
    "\n",
    "    getted_news = 0\n",
    "    \n",
    "    total_news = API_INGURU(url, 1, data_inicial, data_final)['pagination']['total']\n",
    "\n",
    "    \n",
    "    if not total_news:\n",
    "      parcial_data_inicial = data_inicial\n",
    "      parcial_data_final = data_final\n",
    "      dados = {\n",
    "        'author': np.nan,\n",
    "        'content': np.nan,\n",
    "        'crawled_date': np.nan,\n",
    "        'domain': np.nan,\n",
    "        'id': np.nan,\n",
    "        'published_date': np.nan,\n",
    "        'source': np.nan,\n",
    "        'source_country': np.nan,\n",
    "        'source_state': np.nan,\n",
    "        'subtitle': np.nan,\n",
    "        'title': np.nan,\n",
    "        'url': np.nan,\n",
    "        'dh_insertion_raw': np.nan\n",
    "      }\n",
    "      fail_df = pd.DataFrame(dados, index=[0])\n",
    "      array_dfs.append(fail_df)\n",
    "      parcial_data_inicial = parcial_data_final\n",
    "      parcial_data_final = data_final\n",
    "    else:\n",
    "      \n",
    "      print('Total de notícias: ', total_news)\n",
    "\n",
    "      parcial_data_inicial = data_inicial\n",
    "      parcial_data_final = data_final\n",
    "\n",
    "      while getted_news < total_news:\n",
    "\n",
    "          parcial_news = total_news\n",
    "\n",
    "          while parcial_news > 10000:\n",
    "              print('Parcial de notícias: ', parcial_news)\n",
    "              parcial_data_inicial, parcial_data_final = divide_data(parcial_data_inicial, parcial_data_final)\n",
    "              parcial_news = API_INGURU(url, 1, parcial_data_inicial, parcial_data_final)['pagination']['total']\n",
    "\n",
    "          print(\"fazendo requisicao\")\n",
    "          print('Data inicial: ', parcial_data_inicial)\n",
    "          print('Data final: ', parcial_data_final)\n",
    "          news = API_INGURU(url, parcial_news, parcial_data_inicial, parcial_data_final)['data']\n",
    "\n",
    "          #CRIA UM DATAFRAME COM AS NOTICIAS\n",
    "          noticias = pd.DataFrame(news)\n",
    "          #ADICIONA NUM ARRAY DE DATAFRAME\n",
    "          array_dfs.append(noticias)\n",
    "\n",
    "          #corrige as datas\n",
    "\n",
    "          parcial_data_inicial = parcial_data_final\n",
    "          parcial_data_final = data_final\n",
    "\n",
    "          getted_news += parcial_news\n",
    "          \n",
    "\n",
    "    return pd.concat(array_dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8dd385f17f0b7e9f1e290bee991f193fd8a475a8074cd056cfac05fc1e52032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
