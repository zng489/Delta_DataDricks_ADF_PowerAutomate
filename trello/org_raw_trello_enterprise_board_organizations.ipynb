{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0388ca7-a5ee-4c30-93d3-104085045d3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cni_connectors import adls_gen1_connector as adls_conn\n",
    "var_adls_uri = adls_conn.adls_gen1_connect(spark, dbutils, scope=\"adls_gen2\", dynamic_overwrite=\"dynamic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16f47dcd-4824-4c94-a576-ba3da96bc5d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests, zipfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "import subprocess\n",
    "from threading import Timer\n",
    "import shlex\n",
    "import logging\n",
    "import json\n",
    "from core.bot import log_status\n",
    "from core.adls import upload_file\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "import re\n",
    "import shlex\n",
    "import time\n",
    "from time import strftime\n",
    "from datetime import datetime\n",
    "from datetime import datetime, date\n",
    "from unicodedata import normalize\n",
    "from collections import namedtuple\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, BooleanType\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1607d078-3cb5-47be-b894-58c3d283715c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = json.loads(re.sub(\"\\\"\", \"\\\"\", dbutils.widgets.get(\"params\")))\n",
    "dls = json.loads(re.sub(\"\\\"\", \"\\\"\", dbutils.widgets.get(\"dls\")))\n",
    "adf = json.loads(re.sub(\"\\\"\", \"\\\"\", dbutils.widgets.get(\"adf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd52e4a4-6138-402b-b3ee-aa052ee25492",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def limpaUnicode(df, campo):\n",
    "  df[campo] = df[campo].str.replace(\"\\u2705\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u2726\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\U0001f525\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\U0001f680\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\U0001f44d\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u201c\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u201d\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\U0001f446\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u2013\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u2022\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\uf0a7\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u0301\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u0327\", \"\")\n",
    "  df[campo] = df[campo].str.replace(\"\\u0303\", \"\")\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6deac363-d961-46ba-b2bf-68da18b828b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"{uri}/tmp/dev/lnd/crw/trello/config/API_TOKEN.csv\".format(uri=var_adls_uri)\n",
    "trello = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"sep\", \";\").load(path)\n",
    "trello = trello.filter(trello[\"AREA\"] == \"UNIEPRO\").collect()\n",
    "\n",
    "for row in trello:\n",
    "    AREA = row[0]\n",
    "    TOKEN = row[1]\n",
    "    CHAVE = row[2]\n",
    "    USUARIO = row[3]\n",
    "\n",
    "area = AREA\n",
    "key = CHAVE\n",
    "token = TOKEN\n",
    "idMember = USUARIO\n",
    "area = AREA\n",
    "area_ = AREA\n",
    "\n",
    "\n",
    "\n",
    "tmp_enterprise = \"trello__enterprise\"\n",
    "tmp_board = \"trello__board\"\n",
    "tmp_organizations = \"trello__organizations\"\n",
    "\n",
    "os.makedirs(tmp_enterprise, mode=0o777, exist_ok=True)\n",
    "os.makedirs(tmp_board, mode=0o777, exist_ok=True)\n",
    "os.makedirs(tmp_organizations, mode=0o777, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "url_api_board = \"https://api.trello.com/1/members/me?key={0}&token={1}\";\n",
    "t = requests.Session()\n",
    "response = t.get(url_api_board.format(key, token), verify=False)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "  try:\n",
    "    dados = response.json()\n",
    "    df = pd.json_normalize(dados)\n",
    "    df[\"area\"] = area_\n",
    "    df1 = df[[\"area\", \"idEnterprise\", \"idOrganizations\", \"id\", \"idMemberReferrer\", \"username\", \"fullName\", \"initials\", \"email\", \"idBoards\"]]\n",
    "\n",
    "    df1 = df1.astype({\"idMemberReferrer\": \"string\", \"idBoards\": \"string\", \"idOrganizations\": \"string\"})\n",
    "    df1 = df1.rename(columns={\"id\": \"idMember\"})\n",
    "  except Exception as e:\n",
    "    print(\"get_member_token: area:{0} - ERROR: {1}\".format(area_, e))\n",
    "    logging.info(\"get_member_token: area:{0} - ERROR: {1}\".format(area_, e))\n",
    "\n",
    "  membro = df1\n",
    "  membro.to_parquet(f\"{tmp_enterprise}/enterprise.parquet\", compression=\"snappy\")\n",
    "\n",
    "  membro = pd.read_parquet(f\"{tmp_enterprise}/enterprise.parquet\")\n",
    "  idMember = membro[\"idMember\"][0]\n",
    "  dados_enterprise = spark.createDataFrame(membro)\n",
    "\n",
    "  schema = \"oni/trello\"\n",
    "  table = \"enterprise\"\n",
    "  upload_file(spark=spark, dbutils=dbutils, df=dados_enterprise, schema=schema, table=table)\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    shutil.rmtree(tmp_enterprise)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "  url_api_board = \"https://api.trello.com/1/members/{0}/boards?key={1}&token={2}&cards=all\";\n",
    "  t = requests.Session()\n",
    "  df1 = pd.DataFrame()\n",
    "\n",
    "  try:\n",
    "    response = t.get(url_api_board.format(idMember, key, token), verify=False)\n",
    "    dados = response.json()\n",
    "    df = pd.json_normalize(dados)\n",
    "    df = limpaUnicode(df, \"name\")\n",
    "    df = limpaUnicode(df, \"desc\")\n",
    "    df[\"area\"] = area_\n",
    "\n",
    "    df1 = df[\n",
    "      [\"area\", \"id\", \"name\", \"desc\", \"dateLastActivity\", \"starred\", \"url\", \"shortUrl\", \"shortLink\", \"idMemberCreator\", \"idOrganization\",\n",
    "      \"idEnterprise\", \"closed\", \"labelNames.green\", \"labelNames.yellow\", \"labelNames.orange\", \"labelNames.red\", \"labelNames.purple\",\n",
    "      \"labelNames.blue\", \"labelNames.sky\", \"labelNames.lime\", \"labelNames.pink\", \"labelNames.black\", \"labelNames.green_dark\",\n",
    "      \"labelNames.yellow_dark\", \"labelNames.orange_dark\", \"labelNames.red_dark\", \"labelNames.purple_dark\", \"labelNames.blue_dark\",\n",
    "      \"labelNames.sky_dark\", \"labelNames.lime_dark\", \"labelNames.pink_dark\", \"labelNames.black_dark\", \"labelNames.green_light\",\n",
    "      \"labelNames.yellow_light\", \"labelNames.orange_light\", \"labelNames.red_light\", \"labelNames.purple_light\", \"labelNames.blue_light\",\n",
    "      \"labelNames.sky_light\", \"labelNames.lime_light\", \"labelNames.pink_light\", \"labelNames.black_light\"]]\n",
    "\n",
    "    df1 = df1.astype({\"idEnterprise\":\"string\"})\n",
    "    df1 = df1.rename(columns={\"id\": \"idBoard\"})\n",
    "  except Exception as e:\n",
    "    print(\"detalhe_lista_boards_por_members: ERROR: {1}\".format(e))\n",
    "    logging.info(\"detalhe_lista_boards_por_members:  ERROR: {1}\".format(e))\n",
    "\n",
    "  dados = df1\n",
    "  dados[\"idEnterprise\"] = membro[\"idEnterprise\"][0]\n",
    "\n",
    "  if len(dados) > 0:\n",
    "    filename = \"lista_boards_\" + area\n",
    "    dados.to_parquet(f\"{tmp_board}/board.parquet\", compression=\"snappy\")\n",
    "\n",
    "    board = spark.createDataFrame(dados)\n",
    "    schema = \"oni/trello\"\n",
    "    table = \"board\"\n",
    "    upload_file(spark=spark, dbutils=dbutils, df=board, schema=schema, table=table)\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    shutil.rmtree(tmp_board)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "  for row in dados.itertuples():\n",
    "    if row.idBoard == \"63e3ea369ba56d741da36330\" or row.idBoard == \"61e6b049b7ca7305318c5180\": \n",
    "      idBoard = row.idBoard\n",
    "      nome_board = row.name\n",
    "      shortLink_board = row.shortLink\n",
    "      idOrganizations = row.idOrganization\n",
    "    \n",
    "      if shortLink_board != \"-1\":\n",
    "        logging.info(\"BOARD: {0}\".format(nome_board))\n",
    "        \n",
    "\n",
    "        if idOrganizations:\n",
    "          url_api_board = \"https://api.trello.com/1/organizations/{0}?key={1}&token={2}&cards=all\";\n",
    "          t = requests.Session()\n",
    "          response = t.get(url_api_board.format(idOrganizations, key, token), verify=False)\n",
    "          df1 = pd.DataFrame()\n",
    "          try:\n",
    "            dados = response.json()\n",
    "            df = pd.json_normalize(dados)\n",
    "            df[\"area\"] = area_\n",
    "            df[\"idBoard\"] = idBoard\n",
    "            df1 = df[[\"area\", \"idBoard\", \"id\", \"name\", \"displayName\", \"website\", \"teamType\", \"desc\", \"url\", \"logoHash\",\n",
    "                      \"logoUrl\"]]\n",
    "\n",
    "            df1 = df1.astype({\"logoHash\": \"string\", \"logoUrl\": \"string\"})\n",
    "            df1 = df1.rename(columns={\"id\": \"idOrganizations\"})\n",
    "          except Exception as e:\n",
    "            logging.info(\"detalhe_organizations: idOrganizations:{0} - ERROR: {1}\".format(idOrganizations, e))\n",
    "            \n",
    "          dados_organizations = df1\n",
    "          if len(dados_organizations) > 0:\n",
    "            filename = \"boards_organizations_\" + shortLink_board\n",
    "            dados_organizations.to_parquet(f\"{tmp_organizations}/{filename}.parquet\", compression=\"snappy\")\n",
    "            schema = StructType(\n",
    "                [\n",
    "                    StructField(\"area\", StringType(), nullable=True),\n",
    "                    StructField(\"idBoard\", StringType(), nullable=True),\n",
    "                    StructField(\"idOrganizations\", StringType(), nullable=True),\n",
    "                    StructField(\"name\", StringType(), nullable=True),\n",
    "                    StructField(\"displayName\", StringType(), nullable=True),\n",
    "                    StructField(\"website\", IntegerType(), nullable=True),\n",
    "                    StructField(\"teamType\", IntegerType(), nullable=True),\n",
    "                    StructField(\"desc\", StringType(), nullable=True),\n",
    "                    StructField(\"url\", StringType(), nullable=True),\n",
    "                    StructField(\"logoHash\", StringType(), nullable=True),\n",
    "                    StructField(\"logoUrl\", StringType(), nullable=True)\n",
    "                ])\n",
    "            organizations = spark.createDataFrame(dados_organizations, schema=schema)\n",
    "            schema = \"oni/trello\"\n",
    "            table = \"organizations\"\n",
    "            upload_file(spark=spark, dbutils=dbutils, df=organizations, schema=schema, table=table)\n",
    "except Exception as e:\n",
    "    raise e\n",
    "finally:\n",
    "    shutil.rmtree(tmp_organizations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "org_raw_trello_enterprise_board_organizations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
