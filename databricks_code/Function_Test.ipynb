{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd9cf2cb-6dea-4ca8-b379-ec91ccc478e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.Column.html#pyspark.sql.Column\n",
    "'''python\n",
    "\n",
    "from pyspark.sql.functions import when, col,lit, substring .... '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56ed04bc-c4bc-4a68-9490-aef63c28a1c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54433ab7-e96e-430d-9506-32a10b91aa97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Adding(number:'integer')->'Soma':\n",
    "  df = 10 + number\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "143bdc44-f8ef-4fe3-9a7c-8863ee70aa8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.notebook.run(\"notebook_name\", time(in sec) ,{ \" \"db_name\" : \"jmdc_20180731_test\"}) @Christian Rodriguez @jayashree @Roger Erens\n",
    "#\n",
    "#For example:\n",
    "#\n",
    "#dbutils.notebook.run(\"notebook_1\", 600,{ \"db_name\" : \"jmdc_20180731_test\"})\n",
    "#\n",
    "#Please let me know if you do have any issues.\n",
    "#\n",
    "#Mail id : vinayakbhrdwj@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3057e3ed-032b-49d0-9113-e9a71ecb38be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "pip in databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2641269c-8dc7-47a2-a918-2739db218394",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.installPyPI(\"openpyxl\")\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25b76daf-7e04-472e-9181-92524fdd8b29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e563406-0239-4e3a-9bb3-0bf6b9d690cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option('sep', ';').option('encoding', 'ISO-8859-1').load('abfss://datalake@cnibigdatadlsgen2.dfs.core.windows.net/uds/uniepro/data/projecoes-daniel.csv')\n",
    "\n",
    "df.display()\n",
    "\n",
    "df = spark.read.parquet(var_adls_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a26805ec-12f0-447a-a983-2aaa7ab3e5e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9defff1-215c-41cf-a80c-43ca8c4eec7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.coalesce(1).write.option(\"encoding\", \"ISO-8859-1\").option('header','true').csv('abfss://datalake@cnibigdatadlsgen2.dfs.core.windows.net/uds/uniepro/data/dfdfdf', mode='overwrite')\n",
    "\n",
    "or \n",
    "\n",
    "rais_vinculo.coalesce(1).write.format(\"parquet\").option(\"header\", True).save(var_adls_uri + '/uds/uniepro/df_Ind_cresc_eco/raw/Dados/asdasda')\n",
    "\n",
    "or rais_vinculo.repartition(40).write.parquet('abfss://datalake@cnibigdatadlsgen2.dfs.core.windows.net/uds/uniepro/df_Ind_cresc_eco/raw/Dados/asdasda', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c41532b-125d-4cea-885f-ea4a87e31b8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Spark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99728020-9cc6-4243-bb7b-6dfc4b147abb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n",
       "Category| ID| Value|string|Truth|Ponto_Virgula|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "       A|  1|121.44|  true| true|      um,dois|\n",
       "       B|  2|300.01| false|false|  tres_quatro|\n",
       "       C|  3| 10.99|  none| null|    dois,tres|\n",
       "       D|  4| 33.87|  true| true|        cinco|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n|Category| ID| Value|string|Truth|Ponto_Virgula|\n+--------+---+------+------+-----+-------------+\n|       A|  1|121.44|  true| true|      um,dois|\n|       B|  2|300.01| false|false|  tres_quatro|\n|       C|  3| 10.99|  none| null|    dois,tres|\n|       D|  4| 33.87|  true| true|        cinco|\n+--------+---+------+------+-----+-------------+\n\n</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"Category\",\"ID\",\"Value\",\"string\",\"Truth\", 'Ponto_Virgula']\n",
    "data = [(\"A\", 1, 121.44, \"true\", True, 'um,dois'), (\"B\", 2, 300.01, \"false\", False, 'tres_quatro'),\n",
    "        (\"C\", 3, 10.99, \"none\" , None, 'dois,tres'), (\"D\", 4, 33.87, \"true\" , True, 'cinco')]\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88a3c13f-e353-4123-a10d-4cc0dab4e400",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[81]: DataFrame[Category: string, ID: bigint, Value: double, string: string, Truth: boolean]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[81]: DataFrame[Category: string, ID: bigint, Value: double, string: string, Truth: boolean]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8be4ef55-eb17-45ab-bf56-40f953359c4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#     data = [{\"Category\": 'A', \"ID\": 1, \"Value\": 121.44, \"Truth\": True},\n",
    "#             {\"Category\": 'B', \"ID\": 2, \"Value\": 300.01, \"Truth\": False},\n",
    "#             {\"Category\": 'C', \"ID\": 3, \"Value\": 10.99, \"Truth\": None},\n",
    "#             {\"Category\": 'E', \"ID\": 4, \"Value\": 33.87, \"Truth\": True}\n",
    "#             ]\n",
    "#     \n",
    "#     2. Import and create a SparkSession:\n",
    "#     \n",
    "#     from pyspark.sql import SparkSession\n",
    "#     spark = SparkSession.builder.getOrCreate()\n",
    "#     \n",
    "#     3. Create a DataFrame using the createDataFrame method. Check the data type to confirm the variable is a DataFrame:\n",
    "#     \n",
    "#     df = spark.createDataFrame(data)\n",
    "#     type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df2bc026-7263-4b4a-afc1-70ba30a81d12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1- First Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e83010cf-f155-40f0-96c7-30f72d37b912",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be9946b2-cb00-4851-be02-a37b0ffd3969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[123]: &#39;Category&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[123]: &#39;Category&#39;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "527e301d-6a05-4ca6-bb81-faa53e4f62e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[124]: &#39;ID&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[124]: &#39;ID&#39;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60c5ffcf-95fe-4422-ba82-3138f82eee2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7d8aaf7-41b7-44a3-9595-ef0d8c0989a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(column)\n",
    "    df = df.withColumnRenamed(column, DF_1)\n",
    "    '''\n",
    "    df = df.withColumnRenamed('col_1', DF_1)\n",
    "    -> \"df\" must have transformations col_1 contained inside in \"df\"\n",
    "    df = df.withColumnRenamed('col_2', DF_1)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25c84c08-001b-449f-ba15-49fcb2255cd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>New_String Category</th><th>New_String ID</th><th>New_String Value</th><th>New_String string</th><th>New_String Truth</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "New_String Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "New_String ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "New_String Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "New_String string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "New_String Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rename_columns(dataframe):\n",
    "  for column in dataframe.columns:\n",
    "    print(columns)\n",
    "    DF_1 = 'New_String ' + column\n",
    "    dataframe = dataframe.withColumnRenamed(column, DF_1)\n",
    "  return dataframe\n",
    "\n",
    "\n",
    "rename_columns(df).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ee2f9e6-f8e0-40c8-84ce-09d6223fc599",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340f1d50-5605-4a3d-bb77-75a37386a30f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>LOL LOL ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [
        {
         "name": "DATAFRAME_COLUMN_1",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "LOL LOL ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LOL LOL ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rename_columns(column):\n",
    "  DF = 'LOL LOL ' + column\n",
    "  return DF\n",
    "\n",
    "DATAFRAME_COLUMN_1 = df.withColumnRenamed('ID', rename_columns(df.columns[1]))\n",
    "\n",
    "DATAFRAME_COLUMN_1.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd0e45ae-b9bc-4b05-89e5-0b88f9c4ab22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7d91557-c5cc-450d-aa7b-cf6e883d629d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "  df = df.withColumnRenamed(column, cf.normalize_str(column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50066efe-39c3-404c-be67-78a796e10930",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abe16e92-954f-4448-bd47-ab1f411ac05e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [
        {
         "name": "DataFrame_2",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def replace_function(df):\n",
    "  from unicodedata import normalize  \n",
    "  import re\n",
    "  #regex = re.compile(r'[.,;{}()\\n\\t=]')\n",
    "  DF = df + ' Adding_String '\n",
    "  return DF\n",
    "\n",
    "function = udf(lambda x: replace_function(x), StringType() )\n",
    "\n",
    "\n",
    "DataFrame_2 = df.withColumn('Category', function(col('Category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcb4b142-62be-4f0e-bd33-e7437eb50278",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td>A Adding_String </td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B Adding_String </td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C Adding_String </td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D Adding_String </td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A Adding_String ",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B Adding_String ",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C Adding_String ",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D Adding_String ",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c53db6b-d8a6-4fc7-9a0e-0ea017223d92",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f500b48c-0e77-4b2b-8096-aefbc5081705",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>tru REPLACING_VALUES</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>fals REPLACING_VALUES</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>non REPLACING_VALUES</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>tru REPLACING_VALUES</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "tru REPLACING_VALUES",
         true
        ],
        [
         "B",
         2,
         300.01,
         "fals REPLACING_VALUES",
         false
        ],
        [
         "C",
         3,
         10.99,
         "non REPLACING_VALUES",
         null
        ],
        [
         "D",
         4,
         33.87,
         "tru REPLACING_VALUES",
         true
        ]
       ],
       "datasetInfos": [
        {
         "name": "DataFrame_3",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def replace_function(df):\n",
    "  from unicodedata import normalize  \n",
    "  import re\n",
    "  #regex = re.compile(r'[.,;{}()\\n\\t=]')\n",
    "  DF = df.replace('e',' REPLACING_VALUES')\n",
    "  return DF\n",
    "\n",
    "function = udf(lambda x: replace_function(x), StringType() )\n",
    "\n",
    "DataFrame_3 = df.withColumn('string', function(col('string')))\n",
    "DataFrame_3.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1b55d41-19c4-49d6-92be-fa3ec3418f07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed41c6ab-2b25-478e-9c83-feb018399f5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aba3020f-3451-4b14-9105-fdf8a5139bc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "# Use pandas_udf to define a Pandas UDF\n",
    "@pandas_udf('string', PandasUDFType.SCALAR)\n",
    "# Input/output are both a pandas.Series of doubles\n",
    "\n",
    "def pandas_plus_one(df):\n",
    "  from unicodedata import normalize  \n",
    "  import re\n",
    "  DF = df.replace('A',' REPLACING_VALUES')\n",
    "  return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e761ce0c-4893-4e61-b5dc-4ed7cc08c180",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th></tr></thead><tbody><tr><td> REPLACING_VALUES</td><td>1</td><td>121.44</td><td>true</td><td>true</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         " REPLACING_VALUES",
         1,
         121.44,
         "true",
         true
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true
        ]
       ],
       "datasetInfos": [
        {
         "name": "DataFrame_4",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame_4 = df.withColumn('Category', pandas_plus_one(col('Category')))\n",
    "DataFrame_4.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d3aeead-4187-4dce-8ba2-a377f54ce18d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "075d572a-9cef-4fac-a263-029d51f5fc18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unicodedata import normalize  \n",
    "import re\n",
    "\n",
    "regex = re.compile(r'[.,;{}()\\n\\t=]')\n",
    "for col in df.columns:\n",
    "  col_renamed = regex.sub('', normalize('NFKD', col.strip())\n",
    "                          .encode('ASCII', 'ignore')        \n",
    "                          .decode('ASCII')                 \n",
    "                          .replace(' ', '_')                    \n",
    "                          .replace('-', '_'))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bf06c27-af4e-4810-82e0-7523ae5d5f94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "  from unicodedata import normalize  \n",
    "  import re\n",
    "  \n",
    "  regex = re.compile(r'[.,;{}()\\n\\t=]')\n",
    "  for col in df.columns:\n",
    "      col_renamed = regex.sub('', normalize('NFKD', col.strip())\n",
    "                             .encode('ASCII', 'ignore')        \n",
    "                             .decode('ASCII')                 \n",
    "                             .replace(' ', '_')                    \n",
    "                             .replace('-', '_')\n",
    "                             .replace('/', '_')\n",
    "                             .replace('$', 'S')\n",
    "                             .upper())\n",
    "      df = df.withColumnRenamed(col, col_renamed)\n",
    "  return df\n",
    "\n",
    "\n",
    "################################################################\n",
    "# def replace(df):\n",
    "#   text = df.replace('J','ZZZZZZ')\n",
    "#   return text\n",
    "\n",
    "# from pyspark.sql.functions import *\n",
    "# df.withColumn(\"names_replace\", replace(col('names_upper')))\n",
    "# TypeError: 'Column' object is not callable\n",
    "################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4116ffb7-6d73-4c46-8690-679bc2174d89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ef6076-9596-4638-b80f-bbf6fc43a76c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### regex_replace with java regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c0103e-70cc-4ad1-bbda-3005e781ccaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df_teste = df.withColumn('FORMACAO_INICIAL_BASE', round(col('FORMACAO_INICIAL_BASE'),2))\n",
    "df_teste = df.withColumn('FORMACAO_INICIAL_BASE', regexp_replace(col('FORMACAO_INICIAL_BASE'), '\\\\.',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e185a9-b952-406c-b8fa-4fb5a78a5ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a02c47ad-5110-4ccf-8b4f-2c8f55179632",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def replace_function(df):\n",
    "  from unicodedata import normalize  \n",
    "  import re\n",
    "  #regex = re.compile(r'[.,;{}()\\n\\t=]')\n",
    "  DF = df.replace('_',',,,,,,,,,,,,,,,,,,,,,,,')\n",
    "  return DF\n",
    "\n",
    "function = udf(lambda x: replace_function(x), StringType() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81cafd71-e572-4ca7-a539-7994744ab336",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th><th>Ponto_Virgula</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td><td>um,dois</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td><td>tres,,,,,,,,,,,,,,,,,,,,,,,quatro</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td><td>dois,tres</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td><td>cinco</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true,
         "um,dois"
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false,
         "tres,,,,,,,,,,,,,,,,,,,,,,,quatro"
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null,
         "dois,tres"
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true,
         "cinco"
        ]
       ],
       "datasetInfos": [
        {
         "name": "DataFrame_5",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Ponto_Virgula",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame_5 = df.withColumn('Ponto_Virgula', function(f.col('Ponto_Virgula')))\n",
    "DataFrame_5.display()\n",
    "\n",
    "# .withColumn('datafinal', regexp_replace(col('datafinal'), '\\\\{ñ','0'))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1482d005-1567-4c53-8774-e186fa1d49d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    ".withColumn('datafinal', regexp_replace(col('datafinal'), '\\\\{ñ','0'))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79cf1410-acf3-458a-9be2-fb8baac39034",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "import re\n",
    "def removeEmoji(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "punct_remove = udf(lambda s: remove_punct(s))\n",
    "removeEmoji = udf(lambda s: removeEmoji(s))\n",
    "但我得到以下错误:\n",
    "\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-29-e5d42d609b59> in <module>()\n",
    "----> 1 new_df = new_df.withColumn(\"content\", remove_punct(df_merge[\"content\"]))\n",
    "      2 new_df.show(5)\n",
    "<ipython-input-21-dee888ef5b90> in remove_punct(text)\n",
    "      2 \n",
    "      3 def remove_punct(text):\n",
    "----> 4     return text.translate(str.maketrans('', '', string.punctuation))\n",
    "      5 \n",
    "      6 \n",
    "TypeError: 'Column' object is not callable\n",
    "如何解决？有没有其他方法让用户编写的函数在数据帧上运行？\n",
    "\n",
    "谢谢你，)\n",
    "\n",
    "###堆栈跟踪表明您正在直接调用Python方法，而不是udf。\n",
    "\n",
    "remove_punct是一个普通的Python函数，而punct_remove是一个udf，可以用作withColumn调用的第二个参数。\n",
    "\n",
    "解决这个问题的一种方法是在withColumn调用中使用punct_remove而不是remove_punct。\n",
    "\n",
    "另一种减少Python函数和udf混淆的方法是使用@udf注释:\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "@F.udf(returnType=T.StringType())\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "  \n",
    "  \n",
    "df.withColumn(\"content\", remove_punct(F.col(\"content\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f2fab9a-5400-4b2d-b678-b64ff41dc0c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e379a4c-df77-4eda-ac43-5610265b01cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df.select(F.col('col_1'), F.col('col_2'), F.col('col_3'))\n",
    "\n",
    "# or\n",
    "\n",
    "df.select(df.col_1, df.col_2, df.col_3)\n",
    "\n",
    "# or\n",
    "\n",
    "df.select(df['col_1'], df['col_2'], df['col_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b638d29-7454-4f43-87ae-baf0aa849a0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def changeencode(data):\n",
    "  cols = data.columns\n",
    "  for col in cols:\n",
    "    if data[col].dtype == 'O':\n",
    "      data[col] = data[col].str.decode('utf-8').str.encode('ascii', 'ignore')\n",
    "  return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc759a89-f0d8-47ef-8137-d5bfbf96604a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pyspark.sql.Column¶\n",
    "class pyspark.sql.Column(jc)[source]\n",
    "A column in a DataFrame.\n",
    "\n",
    "Column instances can be created by:\n",
    "\n",
    "# 1. Select a column out of a DataFrame\n",
    "df.colName\n",
    "df[\"colName\"]\n",
    "\n",
    "# 2. Create from an expression\n",
    "df.colName + 1\n",
    "1 / df.colName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f03a525-bf2d-4567-9035-103c6e48d3a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def upper(df):\n",
    "  text = df.upper()\n",
    "  return text\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df = df.withColumn(\"names_upper\", upper(f.col('name')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e72ed100-46bb-414a-a2c7-1be174ba6a65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6790e5c7-1212-4091-926d-00581258a092",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# WORKING WITH PYSPARK,SAVING,SQL, and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc9af4ba-5ab0-46cf-8ff8-97e12e7d5303",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2008 = df.filter(f.col('ANO') == 2008).filter(f.col('FL_VINCULO_ATIVO_3112') == 1)\n",
    "print(df_2008.select(\"COUNT_CD_SEXO\").rdd.keys().sum())\n",
    "#print(df_2008.count())\n",
    "df_2008.coalesce(1).write.format(\"parquet\").option(\"header\", \"true\").save('abfss://datalake@cnibigdatadlsgen2.dfs.core.windows.net/uds/uniepro/data/rais_05_10_15_20/rais_25_2008_parquet/', mode='overwrite')\n",
    "df_2008.write.format(\"parquet\").saveAsTable(\"rais_25.rais_25_2008\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0272c321-2ddc-4cc3-bb4f-2ae3d1383c5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "![#c5f015](https://via.placeholder.com/1500x20/ffffff/000000?text=+)\n",
    "\n",
    "### Coding in SQL in DataBricks (PySpark)\n",
    "\n",
    "![#c5f015](https://via.placeholder.com/1500x20/ffffff/000000?text=+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d3f8f0-57a2-47c5-84e5-8bbdeaa3e3e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import databricks.koalas as ks\n",
    "except:\n",
    "  dbutils.library.installPyPI(\"koalas\")\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import datediff,col,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30fcdb02-1bee-471f-9824-76d3534fea60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n",
       "Category| ID| Value|string|Truth|Ponto_Virgula|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "       A|  1|121.44|  true| true|          N/A|\n",
       "       B|  2|300.01| false|false|  tres_quatro|\n",
       "       C|  3| 10.99|  none| null|    dois,tres|\n",
       "       D|  4| 33.87|  true| true|        cinco|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n|Category| ID| Value|string|Truth|Ponto_Virgula|\n+--------+---+------+------+-----+-------------+\n|       A|  1|121.44|  true| true|          N/A|\n|       B|  2|300.01| false|false|  tres_quatro|\n|       C|  3| 10.99|  none| null|    dois,tres|\n|       D|  4| 33.87|  true| true|        cinco|\n+--------+---+------+------+-----+-------------+\n\n</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"Category\",\"ID\",\"Value\",\"string\",\"Truth\", 'Ponto_Virgula']\n",
    "data = [(\"A\", 1, 121.44, \"true\", True, 'N/A'), (\"B\", 2, 300.01, \"false\", False, 'tres_quatro'),\n",
    "        (\"C\", 3, 10.99, \"none\" , None, 'dois,tres'), (\"D\", 4, 33.87, \"true\" , True, 'cinco')]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3e89039-ca2a-429f-8b1d-1ea9dbbd8158",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th><th>Ponto_Virgula</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td><td>N/A</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td><td>tres_quatro</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td><td>dois,tres</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td><td>cinco</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true,
         "N/A"
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false,
         "tres_quatro"
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null,
         "dois,tres"
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true,
         "cinco"
        ]
       ],
       "datasetInfos": [
        {
         "name": "DF_SQL",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        },
        {
         "name": "DF_SQL_Table_Test",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Ponto_Virgula",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_SQL = df\n",
    "\n",
    "\n",
    "# Creating table\n",
    "DF_SQL.createOrReplaceTempView('Table_Test')\n",
    "# table name!!\n",
    "\n",
    "# SQL \n",
    "DF_SQL_Table_Test = spark.sql(\"\"\"SELECT * FROM Table_Test\"\"\")\n",
    "# https://medium.com/analytics-vidhya/beginners-guide-on-databricks-spark-using-python-pyspark-de74d92e4885\n",
    "\n",
    "# Reading table as spark\n",
    "\n",
    "DF_SQL_Table_Test.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79a99593-15f5-4d6a-8778-5b5fb2bf947e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th><th>Ponto_Virgula</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td><td>N/A</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td><td>tres_quatro</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td><td>dois,tres</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td><td>cinco</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true,
         "N/A"
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false,
         "tres_quatro"
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null,
         "dois,tres"
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true,
         "cinco"
        ]
       ],
       "datasetInfos": [
        {
         "name": "DF_D",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Ponto_Virgula",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_D = spark.table(\"\"\"Table_Test\"\"\")\n",
    "#display(diamonds.select(\"*\"))\n",
    "\n",
    "# reading table as spark\n",
    "\n",
    "DF_D.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db0e02a6-73e8-4712-a979-72c8d892ab68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table or view not found: DF_D; line 1 pos 55;\n",
       "'Project [*, 'LPAD('Category, 4, 0) AS Category_LPAD#380]\n",
       "+- 'UnresolvedRelation [DF_D]\n",
       "\n",
       "\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:109)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:95)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:192)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:191)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:191)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:392)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:191)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:95)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:92)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:180)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:203)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:223)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:200)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:91)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:171)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:171)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:92)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:89)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:81)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:103)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:680)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:675)\n",
       "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:672)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:90)\n",
       "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:392)\n",
       "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
       "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
       "\tat scala.collection.immutable.List.map(List.scala:298)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:36)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:143)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:128)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:143)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n",
       "\tat java.lang.Thread.run(Thread.java:748)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.AnalysisException: Table or view not found: DF_D; line 1 pos 55;\n'Project [*, 'LPAD('Category, 4, 0) AS Category_LPAD#380]\n+- 'UnresolvedRelation [DF_D]\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:109)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:95)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:192)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:191)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:191)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:191)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:92)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:180)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:203)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:223)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:200)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:91)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:171)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:89)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:81)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:103)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:101)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:680)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:845)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:675)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:672)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.$anonfun$executeSql$1(SQLDriverLocal.scala:90)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:36)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:143)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:143)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$10(DriverLocal.scala:431)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:239)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:234)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:231)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:48)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:276)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:269)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:48)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:408)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:653)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:598)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:337)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:219)\n\tat java.lang.Thread.run(Thread.java:748)\n",
       "errorSummary": "Error in SQL statement: AnalysisException: Table or view not found: DF_D; line 1 pos 55;\n'Project [*, 'LPAD('Category, 4, 0) AS Category_LPAD#380]\n+- 'UnresolvedRelation [DF_D]\n",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *, LPAD(Category, 4, \"0\") AS Category_LPAD FROM DF_D;\n",
    "\n",
    "IT DOES NOT WORK IT!!!! THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0505748d-acb8-4a88-9e54-050b9fb0c323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [
        {
         "name": "SQL_CBO",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Category_LPAD",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SQL_CBO = spark.sql(\"\"\"SELECT *, LPAD(Category, 4, \"0\") AS Category_LPAD FROM Table_Test\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dac20e5-3a7f-4526-aacb-a24b651b5759",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th><th>Ponto_Virgula</th><th>Category_LPAD</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td><td>N/A</td><td>000A</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td><td>tres_quatro</td><td>000B</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td><td>dois,tres</td><td>000C</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td><td>cinco</td><td>000D</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true,
         "N/A",
         "000A"
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false,
         "tres_quatro",
         "000B"
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null,
         "dois,tres",
         "000C"
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true,
         "cinco",
         "000D"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Ponto_Virgula",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Category_LPAD",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SQL_CBO.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57935949-422b-491c-95e7-c40bbc4ec95d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create database Consultas_ONI\n",
    "\n",
    "drop table Consultas_ONI.tb_aprendiz\n",
    "\n",
    "rais_df1.write.format(\"parquet\").saveAsTable(\"Consultas_ONI.tb_aprendiz\")\n",
    "\n",
    "DROP DATABASE mapa_da_saude\n",
    "\n",
    "SQL_CBO = spark.sql('select * from oni_homolog.saude_catconsolidada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60803fbc-3108-4b75-bf5c-a5c1b94f9d0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").mode(\"overwrite\").saveAsTable(\"mapa_da_saude.dim_geo\")\n",
    "\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"mapa_da_saude.dim_cbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8f62885-7fe4-4052-b0a1-de174de76703",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "![#c5f015](https://via.placeholder.com/1500x20/ffffff/000000?text=+)\n",
    "\n",
    "### Função para buscar as colunas do De/Para e transformar para pyspark\n",
    "\n",
    "![#c5f015](https://via.placeholder.com/1500x20/ffffff/000000?text=+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ffbac00-5d25-461b-b100-b48c6199713b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n",
       "Category| ID| Value|string|Truth|Ponto_Virgula|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "       A|  1|121.44|  true| true|          N/A|\n",
       "       B|  2|300.01| false|false|  tres_quatro|\n",
       "       C|  3| 10.99|  none| null|    dois,tres|\n",
       "       D|  4| 33.87|  true| true|        cinco|\n",
       "+--------+---+------+------+-----+-------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+---+------+------+-----+-------------+\n|Category| ID| Value|string|Truth|Ponto_Virgula|\n+--------+---+------+------+-----+-------------+\n|       A|  1|121.44|  true| true|          N/A|\n|       B|  2|300.01| false|false|  tres_quatro|\n|       C|  3| 10.99|  none| null|    dois,tres|\n|       D|  4| 33.87|  true| true|        cinco|\n+--------+---+------+------+-----+-------------+\n\n</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Category",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "Value",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "string",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Truth",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "Ponto_Virgula",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"Category\",\"ID\",\"Value\",\"string\",\"Truth\", 'Ponto_Virgula']\n",
    "data = [(\"A\", 1, 121.44, \"true\", True, 'N/A'), (\"B\", 2, 300.01, \"false\", False, 'tres_quatro'),\n",
    "        (\"C\", 3, 10.99, \"none\" , None, 'dois,tres'), (\"D\", 4, 33.87, \"true\" , True, 'cinco')]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffc314ab-7fd1-4207-8862-3a2f29338c2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Category</th><th>ID</th><th>Value</th><th>string</th><th>Truth</th><th>Ponto_Virgula</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>121.44</td><td>true</td><td>true</td><td>N/A</td></tr><tr><td>B</td><td>2</td><td>300.01</td><td>false</td><td>false</td><td>tres_quatro</td></tr><tr><td>C</td><td>3</td><td>10.99</td><td>none</td><td>null</td><td>dois,tres</td></tr><tr><td>D</td><td>4</td><td>33.87</td><td>true</td><td>true</td><td>cinco</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         121.44,
         "true",
         true,
         "N/A"
        ],
        [
         "B",
         2,
         300.01,
         "false",
         false,
         "tres_quatro"
        ],
        [
         "C",
         3,
         10.99,
         "none",
         null,
         "dois,tres"
        ],
        [
         "D",
         4,
         33.87,
         "true",
         true,
         "cinco"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Value",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Truth",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Ponto_Virgula",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c44fad0f-03de-4a23-baba-695b4bfbcdc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4c44801-1f45-4da5-a15a-457f168482bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[17]: [Row(Category=&#39;A&#39;), Row(Category=&#39;B&#39;), Row(Category=&#39;C&#39;), Row(Category=&#39;D&#39;)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[17]: [Row(Category=&#39;A&#39;), Row(Category=&#39;B&#39;), Row(Category=&#39;C&#39;), Row(Category=&#39;D&#39;)]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.select(f.col('Category')).collect()\n",
    "\n",
    "#.first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c64eb1b-756c-48d7-aa24-af80824fed7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Category\n",
       "dasd\n",
       "ID\n",
       "dasd\n",
       "Value\n",
       "dasd\n",
       "string\n",
       "dasd\n",
       "Truth\n",
       "dasd\n",
       "Ponto_Virgula\n",
       "dasd\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Category\ndasd\nID\ndasd\nValue\ndasd\nstring\ndasd\nTruth\ndasd\nPonto_Virgula\ndasd\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "  print(column)\n",
    "  if df.select(f.col(column)).collect() == \"N/A\":\n",
    "    prin(\"N/A\")\n",
    "  else:\n",
    "    print('dasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2aed26d1-6f30-45a6-ae23-19dcb820307c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_list = df.select(\"name\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46945f5f-dd71-4a34-a13d-d1fb7c56ced1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  for column, destination, _type in de_para_values[sheet]:\n",
    "    if column == 'N/A':\n",
    "        yield f.lit(None).cast(_type).alias(destination)\n",
    "    else:\n",
    "      col = f.col(column)\n",
    "      if _type.lower() in ['decimal', 'double']:\n",
    "        col = f.regexp_replace(column, ',', '.')\n",
    "      yield col.cast(_type).alias(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "002b5170-6135-4038-a8db-9c06c225bae7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def select_columns_de_para(dataframe, de_para_adl_path, sheet):\n",
    "  headers = {'name_header':'Tabela Origem','pos_header':'B','pos_org':'C','pos_dst':'E','pos_type':'F'}\n",
    "  de_para_values = cf.parse_ba_doc(dbutils, de_para_adl_path, headers)\n",
    "  \n",
    "  cf.check_ba_doc(dataframe, de_para_values, sheet)\n",
    "  \n",
    "  for column, destination, _type in de_para_values[sheet]:\n",
    "    if column == 'N/A':\n",
    "        yield f.lit(None).cast(_type).alias(destination)\n",
    "    else:\n",
    "      col = f.col(column)\n",
    "      if _type.lower() in ['decimal', 'double']:\n",
    "        col = f.regexp_replace(column, ',', '.')\n",
    "      yield col.cast(_type).alias(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39c4e66f-03de-474e-ae64-266dc629740b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecc98089-3acd-4007-b654-969df16de7a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import crawler.functions as cf\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74bb4d0f-2a95-4a4f-939b-2c02aea141aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.select(*select_columns_de_para(df, de_para_path, sheet='2019'))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Function_Test",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
